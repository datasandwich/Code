{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-04e617e0bd78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_euro_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'34187551-GCST90014288-GO_0007568.h.tsv.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata_euro_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'34187551-GCST90014289-GO_0007568.h.tsv.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata_euro_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'34187551-GCST90014290-GO_0007568.h.tsv.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdata_euro_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'34187551-GCST90014292-GO_0007568.h.tsv.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2155\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2156\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[0muncompress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconsumed_tail\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconsumed_tail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.chdir(\"/Volumes/Google Drive/My Drive/PROJECT/Data/Aging Biomarkers/European\")\n",
    "\n",
    "data_euro_1 = pd.read_csv('34187551-GCST90014288-GO_0007568.h.tsv.gz', sep='\\t')\n",
    "data_euro_2 = pd.read_csv('34187551-GCST90014289-GO_0007568.h.tsv.gz', sep='\\t')\n",
    "data_euro_3 = pd.read_csv('34187551-GCST90014290-GO_0007568.h.tsv.gz', sep='\\t')\n",
    "data_euro_4 = pd.read_csv('34187551-GCST90014292-GO_0007568.h.tsv.gz', sep='\\t')\n",
    "\n",
    "os.chdir(\"/Volumes/Google Drive/My Drive/PROJECT/Data/Aging Biomarkers/African\")\n",
    "\n",
    "data_afri_1 = pd.read_csv('34187551-GCST90014294-GO_0007568.h.tsv.gz', sep='\\t')\n",
    "data_afri_2 = pd.read_csv('34187551-GCST90014295-GO_0007568.h.tsv.gz', sep='\\t')\n",
    "data_afri_3 = pd.read_csv('34187551-GCST90014296-GO_0007568.h.tsv.gz', sep='\\t')\n",
    "data_afri_4 = pd.read_csv('34187551-GCST90014298-GO_0007568.h.tsv.gz', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Indices(data1, data2, data3, data4):\n",
    "    \n",
    "    # Resetting the index\n",
    "    data1.index = np.arange(len(data1))\n",
    "    data2.index = np.arange(len(data2))\n",
    "    data3.index = np.arange(len(data3))\n",
    "    data4.index = np.arange(len(data4))\n",
    "\n",
    "    # Isolating chromosomes\n",
    "    snp_index_1 = []\n",
    "    snp_index_2 = []\n",
    "    snp_index_3 = []\n",
    "    snp_index_4 = []\n",
    "\n",
    "    for i in range(23):\n",
    "        snp_index_1.append(data1.hm_rsid.loc[np.where(data1.hm_chrom==i+1)])\n",
    "        snp_index_2.append(data2.hm_rsid.loc[np.where(data2.hm_chrom==i+1)])\n",
    "        snp_index_3.append(data3.hm_rsid.loc[np.where(data3.hm_chrom==i+1)])\n",
    "        snp_index_4.append(data4.hm_rsid.loc[np.where(data4.hm_chrom==i+1)])\n",
    "        \n",
    "    snp_index_aloha = []\n",
    "\n",
    "    for i in range(23):\n",
    "        l1 = list(set(snp_index_1[i]).intersection(snp_index_2[i]))\n",
    "        l2 = list(set(l1).intersection(snp_index_3[i]))\n",
    "        l3 = list(set(l2).intersection(snp_index_4[i]))\n",
    "\n",
    "        snp_index_aloha.append(pd.Series(l3).dropna())\n",
    "    \n",
    "    # Isolating SNP Subsets\n",
    "    filtered_snp_index_1 = []\n",
    "    filtered_snp_index_2 = []\n",
    "    filtered_snp_index_3 = []\n",
    "    filtered_snp_index_4 = []\n",
    "\n",
    "\n",
    "    for i in range(23):\n",
    "        filtered_snp_index_1.append(list(set(data1.hm_rsid.loc[np.where(data1.p_value<0.3)]).intersection(snp_index_aloha[i])))\n",
    "        filtered_snp_index_2.append(list(set(data2.hm_rsid.loc[np.where(data2.p_value<0.3)]).intersection(snp_index_aloha[i])))\n",
    "        filtered_snp_index_3.append(list(set(data3.hm_rsid.loc[np.where(data3.p_value<0.3)]).intersection(snp_index_aloha[i])))\n",
    "        filtered_snp_index_4.append(list(set(data4.hm_rsid.loc[np.where(data4.p_value<0.3)]).intersection(snp_index_aloha[i])))\n",
    "    \n",
    "    snp_index_aloha_filtered = []\n",
    "    for i in range(23):\n",
    "        l1 = list(set(filtered_snp_index_1[i]).intersection(filtered_snp_index_2[i]))\n",
    "        l2 = list(set(l1).intersection(filtered_snp_index_3[i]))\n",
    "        l3 = list(set(l2).intersection(filtered_snp_index_4[i]))\n",
    "\n",
    "        snp_index_aloha_filtered.append(pd.Series(l3).dropna())\n",
    "        \n",
    "    return(snp_index_aloha, snp_index_aloha_filtered)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Export(data1, data2, data3, data4):\n",
    "    \n",
    "    snp_index_aloha, snp_index_aloha_filtered = Create_Indices(data1, data2, data3, data4)\n",
    "\n",
    "    data1.index = data1.hm_rsid\n",
    "    data2.index = data2.hm_rsid\n",
    "    data3.index = data3.hm_rsid\n",
    "    data4.index = data4.hm_rsid\n",
    "    \n",
    "    for CHROM in range(23):\n",
    "    \n",
    "    \n",
    "        data_1_full = data1.loc[snp_index_aloha[CHROM]]\n",
    "        data_2_full = data2.loc[snp_index_aloha[CHROM]]\n",
    "        data_3_full = data3.loc[snp_index_aloha[CHROM]]\n",
    "        data_4_full = data4.loc[snp_index_aloha[CHROM]]\n",
    "\n",
    "        data_1_filtered = data1.loc[snp_index_aloha_filtered[CHROM]]\n",
    "        data_2_filtered = data2.loc[snp_index_aloha_filtered[CHROM]]\n",
    "        data_3_filtered = data3.loc[snp_index_aloha_filtered[CHROM]]\n",
    "        data_4_filtered = data4.loc[snp_index_aloha_filtered[CHROM]]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        TRAIT_1_full = data_1_full[\n",
    "        ['hm_other_allele','hm_effect_allele','beta','standard_error']\n",
    "        ]\n",
    "        TRAIT_1_full=TRAIT_1_full.rename(columns={\n",
    "                                    \"hm_other_allele\":\"allele_0\",\n",
    "                                    \"hm_effect_allele\":\"allele_1\",\n",
    "                                    \"beta\":\"trait1_b\",\n",
    "                                    \"standard_error\":'trait1_se'})\n",
    "        TRAIT_2_full = data_2_full[\n",
    "        ['beta','standard_error']\n",
    "        ]\n",
    "        TRAIT_3_full = data_3_full[\n",
    "        ['beta','standard_error']\n",
    "        ]\n",
    "        TRAIT_4_full = data_4_full[\n",
    "        ['beta','standard_error']\n",
    "        ]\n",
    "\n",
    "        S_XY_full = TRAIT_1_full\n",
    "        S_XY_full['trait2_b']=TRAIT_2_full['beta']\n",
    "        S_XY_full['trait2_se']=TRAIT_2_full['standard_error']\n",
    "        S_XY_full['trait3_b']=TRAIT_3_full['beta']\n",
    "        S_XY_full['trait3_se']=TRAIT_3_full['standard_error']\n",
    "        S_XY_full['trait4_b']=TRAIT_4_full['beta']\n",
    "        S_XY_full['trait4_se']=TRAIT_4_full['standard_error']\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        TRAIT_1_filtered = data_1_filtered[\n",
    "        ['hm_other_allele','hm_effect_allele','beta','standard_error']\n",
    "        ]\n",
    "        TRAIT_1_filtered=TRAIT_1_filtered.rename(columns={\n",
    "                                    \"hm_other_allele\":\"allele_0\",\n",
    "                                    \"hm_effect_allele\":\"allele_1\",\n",
    "                                    \"beta\":\"trait1_b\",\n",
    "                                    \"standard_error\":'trait1_se'})\n",
    "        TRAIT_2_filtered = data_2_filtered[\n",
    "        ['beta','standard_error']\n",
    "        ]\n",
    "        TRAIT_3_filtered = data_3_filtered[\n",
    "        ['beta','standard_error']\n",
    "        ]\n",
    "        TRAIT_4_filtered = data_4_filtered[\n",
    "        ['beta','standard_error']\n",
    "        ]\n",
    "\n",
    "        S_XY_filtered = TRAIT_1_filtered\n",
    "        S_XY_filtered['trait2_b']=TRAIT_2_filtered['beta']\n",
    "        S_XY_filtered['trait2_se']=TRAIT_2_filtered['standard_error']\n",
    "        S_XY_filtered['trait3_b']=TRAIT_3_filtered['beta']\n",
    "        S_XY_filtered['trait3_se']=TRAIT_3_filtered['standard_error']\n",
    "        S_XY_filtered['trait4_b']=TRAIT_4_filtered['beta']\n",
    "        S_XY_filtered['trait4_se']=TRAIT_4_filtered['standard_error']\n",
    "    \n",
    "    \n",
    "        #S_XY Export\n",
    "        S_XY_full.to_csv('Jupyter_Exports/Meta/S_XY_full{}.csv'.format(CHROM),index=True)\n",
    "        S_XY_filtered.to_csv('Jupyter_Exports/Meta2/S_XY_filtered{}.csv'.format(CHROM),index=True)\n",
    "        \n",
    "        print(\"Chromosom {} complete\".format(CHROM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Subsets(data1, data2, data3, data4):\n",
    "    \n",
    "    snp_index_aloha, snp_index_aloha_filtered = Create_Indices(data1, data2, data3, data4)\n",
    "    \n",
    "    data1.index = data1.hm_rsid\n",
    "    data2.index = data2.hm_rsid\n",
    "    data3.index = data3.hm_rsid\n",
    "    data4.index = data4.hm_rsid\n",
    "    \n",
    "    Created_Subsets = []\n",
    "    \n",
    "    for CHROM in range(23):\n",
    "    \n",
    "  \n",
    "\n",
    "        data_1_filtered = data1.loc[snp_index_aloha_filtered[CHROM]]\n",
    "        data_2_filtered = data2.loc[snp_index_aloha_filtered[CHROM]]\n",
    "        data_3_filtered = data3.loc[snp_index_aloha_filtered[CHROM]]\n",
    "        data_4_filtered = data4.loc[snp_index_aloha_filtered[CHROM]]\n",
    "\n",
    "\n",
    "        TRAIT_1_filtered = data_1_filtered[\n",
    "        ['hm_other_allele','hm_effect_allele','beta','standard_error']\n",
    "        ]\n",
    "        TRAIT_1_filtered=TRAIT_1_filtered.rename(columns={\n",
    "                                    \"hm_other_allele\":\"allele_0\",\n",
    "                                    \"hm_effect_allele\":\"allele_1\",\n",
    "                                    \"beta\":\"trait1_b\",\n",
    "                                    \"standard_error\":'trait1_se'})\n",
    "        TRAIT_2_filtered = data_2_filtered[\n",
    "        ['beta','standard_error']\n",
    "        ]\n",
    "        TRAIT_3_filtered = data_3_filtered[\n",
    "        ['beta','standard_error']\n",
    "        ]\n",
    "        TRAIT_4_filtered = data_4_filtered[\n",
    "        ['beta','standard_error']\n",
    "        ]\n",
    "\n",
    "        S_XY_filtered = TRAIT_1_filtered\n",
    "        S_XY_filtered['trait2_b']=TRAIT_2_filtered['beta']\n",
    "        S_XY_filtered['trait2_se']=TRAIT_2_filtered['standard_error']\n",
    "        S_XY_filtered['trait3_b']=TRAIT_3_filtered['beta']\n",
    "        S_XY_filtered['trait3_se']=TRAIT_3_filtered['standard_error']\n",
    "        S_XY_filtered['trait4_b']=TRAIT_4_filtered['beta']\n",
    "        S_XY_filtered['trait4_se']=TRAIT_4_filtered['standard_error']\n",
    "    \n",
    "    \n",
    "     \n",
    "        Created_Subsets.append(S_XY_filtered)\n",
    "        \n",
    "        print(\"Chromosome {} complete\".format(CHROM+1))\n",
    "        \n",
    "    return(Created_Subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Subset overlap between populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Overlap(Afri_Subsets, Euro_Subsets):\n",
    "    lengths = []\n",
    "    indices = []\n",
    "    for CHROM in range(23):\n",
    "\n",
    "    #os.chdir(\"/Volumes/Google Drive/My Drive/PROJECT/Data/Aging Biomarkers/African/Jupyter_Exports/Meta\")\n",
    "\n",
    "        afri_chrom_filtered = Afri_Subsets[CHROM]\n",
    "    #afri_chrom_full = pd.read_csv('S_XY_full{}.csv'.format(CHROM))\n",
    "    \n",
    "\n",
    "\n",
    "    #os.chdir(\"/Volumes/Google Drive/My Drive/PROJECT/Data/Aging Biomarkers/European/Jupyter_Exports/Meta\")\n",
    "\n",
    "        eu_chrom_filtered = Euro_Subsets[CHROM]\n",
    "    #eu_chrom_full = pd.read_csv('S_XY_full{}.csv'.format(CHROM))\n",
    "\n",
    "        snp_index_fil_eu = eu_chrom_filtered.index\n",
    "        snp_index_fil_afri = afri_chrom_filtered.index\n",
    "\n",
    "    #snp_index_ful_eu = eu_chrom_full.hm_rsid\n",
    "    #snp_index_ful_afri = afri_chrom_full.hm_rsid\n",
    "    \n",
    "        l1 = list(set(snp_index_fil_eu).intersection(snp_index_fil_afri))\n",
    "    #l2 = list(set(snp_index_ful_eu).intersection(snp_index_ful_afri))\n",
    "    \n",
    "        print(len(l1))\n",
    "        indices.append(l1)\n",
    "        lengths.append(len(l1))\n",
    "    \n",
    "    return(indices, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Export_Meta(Afri_Subsets, Euro_Subsets):\n",
    "    \n",
    "    Indices, Lengths = Overlap(Afri_Subsets, Euro_Subsets)\n",
    "\n",
    "    for CHROM in range(23):\n",
    "        afri_chrom_filtered = Afri_Subsets[CHROM]\n",
    "    \n",
    "        eu_chrom_filtered = Euro_Subsets[CHROM]\n",
    "\n",
    "    \n",
    "        eu_chrom_filtered.index = eu_chrom_filtered.index\n",
    "    #eu_chrom_full.index = eu_chrom_full.hm_rsid\n",
    "    \n",
    "        afri_chrom_filtered.index = afri_chrom_filtered.index\n",
    "    #afri_chrom_full.index = afri_chrom_full.hm_rsid\n",
    "\n",
    "        os.chdir(\"/Volumes/Google Drive/My Drive/PROJECT/Data/Aging Biomarkers/European/Jupyter_Exports/META/0.3\")\n",
    "\n",
    "        META_S_XY_filtered = eu_chrom_filtered.loc[Indices[CHROM]]#.drop('hm_rsid',axis=1)\n",
    "    #META_S_XY_full = eu_chrom_full.loc[l2].drop('hm_rsid',axis=1)\n",
    "    \n",
    "        META_S_XY_filtered.to_csv('META_S_XY_filtered{}.csv'.format(CHROM))\n",
    "    #META_S_XY_full.to_csv('META_S_XY_full{}.csv'.format(CHROM))\n",
    "    \n",
    "    #eu_chrom_full.index = np.arange(len(eu_chrom_full))\n",
    "    #META_S_XY_full_chunk_1 = eu_chrom_full.loc[:100]\n",
    "    #META_S_XY_full_chunk_1.index = eu_chrom_full.hm_rsid.loc[:100]\n",
    "\n",
    "    #META_S_XY_full_chunk_1.drop('hm_rsid',axis=1).to_csv('META_S_XY_full_chunk{}.csv'.format(CHROM))\n",
    "\n",
    "    \n",
    "        os.chdir(\"/Volumes/Google Drive/My Drive/PROJECT/Data/Aging Biomarkers/African/Jupyter_Exports/META/0.3\")\n",
    "\n",
    "        META_S_XY_filtered = afri_chrom_filtered.loc[Indices[CHROM]]#.drop('hm_rsid',axis=1)\n",
    "    #META_S_XY_full = afri_chrom_full.loc[l2].drop('hm_rsid',axis=1)\n",
    "\n",
    "        META_S_XY_filtered.to_csv('META_S_XY_filtered{}.csv'.format(CHROM))\n",
    "    #META_S_XY_full.to_csv('META_S_XY_full{}.csv'.format(CHROM))\n",
    "    \n",
    "    #afri_chrom_full.index = np.arange(len(afri_chrom_full))\n",
    "    #META_S_XY_full_chunk_1 = afri_chrom_full.loc[:100]\n",
    "    #META_S_XY_full_chunk_1.index = afri_chrom_full.hm_rsid.loc[:100]\n",
    "\n",
    "    #META_S_XY_full_chunk_1.drop('hm_rsid',axis=1).to_csv('META_S_XY_full_chunk{}.csv'.format(CHROM))\n",
    "    print(Lengths)\n",
    "    return(Lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### European cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export(data_euro_1,data_euro_2,data_euro_3,data_euro_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Euro_Subsets = Create_Subsets(data_euro_1, data_euro_2, data_euro_3, data_euro_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### African American cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export(data_afri_1,data_afri_2,data_afri_3,data_afri_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Afri_Subsets = Create_Subsets(data_afri_1, data_afri_2, data_afri_3, data_afri_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lengths = Export(Afri_Subsets, Euro_Subsets)\n",
    "\n",
    "plt.figure(figsize =(15,5) )\n",
    "sns.lineplot(np.arange(23),Lengths)\n",
    "plt.ylabel('Quantity of SNPs')\n",
    "plt.xlabel('Chromosome ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Volumes/Google Drive/My Drive/PROJECT/Data/Aging Biomarkers/Meta_Analysis\")\n",
    "\n",
    "result = []\n",
    "p_value = []\n",
    "significant_p_value = []\n",
    "for CHROM in range(23):\n",
    "    results = pd.read_csv('0.15/0.15_Meta_Results_Chrom_{}.csv'.format(CHROM+1),index_col=0)\n",
    "    \n",
    "    p_values = 10**(-results['-log10(p-val)'])\n",
    "    p_value.append(p_values)\n",
    "    print(\"Number of significant associations in Chromosome {} BEFORE correction: \".format(CHROM+1)\n",
    "          ,len(p_values.iloc[np.where(p_values<0.05)]))\n",
    "    \n",
    "    adjusted_p_values = p_values*len(data1)\n",
    "    significant_p_value.extend(results.index[np.where(adjusted_p_values<0.05)])\n",
    "\n",
    "    p_values_corrected = adjusted_p_values.iloc[np.where(adjusted_p_values<0.05)]\n",
    "    print(\"Number of significant associations in Chromosome {} AFTER correction: \".format(CHROM+1),len(p_values_corrected))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Published Associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://www.ebi.ac.uk/gwas/rest/api/efoTraits/GO_0007568/associations')\n",
    "GWAS_EBI=response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_snps=[]\n",
    "for i in range(len(GWAS_EBI['_embedded']['associations'])):\n",
    "    published_snps.append(GWAS_EBI['_embedded']['associations'][i]['loci'][0]['strongestRiskAlleles'][0]['riskAlleleName'])\n",
    "    \n",
    "print(\"Number of PUBLISHED significant associations: \",len(published_snps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting GWAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.index = data1.hm_rsid\n",
    "data2.index = data2.hm_rsid\n",
    "data3.index = data3.hm_rsid\n",
    "data4.index = data4.hm_rsid\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "sns.scatterplot(x=data1.loc[list(filtered_snp_index_1[0])].hm_chrom,y=-np.log10(data1.loc[list(filtered_snp_index_1[0])].p_value),color='b',label=\"GrimAge\")\n",
    "sns.scatterplot(x=data2.loc[list(filtered_snp_index_2[0])].hm_chrom,y=-np.log10(data2.loc[list(filtered_snp_index_2[0])].p_value),color='r',label=\"Hannum\")\n",
    "sns.scatterplot(x=data3.loc[list(filtered_snp_index_3[0])].hm_chrom,y=-np.log10(data3.loc[list(filtered_snp_index_3[0])].p_value),color='g',label=\"Epigenetic\")\n",
    "sns.scatterplot(x=data4.loc[list(filtered_snp_index_4[0])].hm_chrom,y=-np.log10(data4.loc[list(filtered_snp_index_4[0])].p_value),color='y',label=\"PhenoAge\")\n",
    "\n",
    "for i in range(22):\n",
    "    sns.scatterplot(x=data1.loc[list(filtered_snp_index_1[i+1])].hm_chrom,y=-np.log10(data1.loc[list(filtered_snp_index_1[i+1])].p_value),color='b')#,label=\"GrimAge\")\n",
    "    sns.scatterplot(x=data2.loc[list(filtered_snp_index_2[i+1])].hm_chrom,y=-np.log10(data2.loc[list(filtered_snp_index_2[i+1])].p_value),color='r')#,label=\"Hannum\")\n",
    "    sns.scatterplot(x=data3.loc[list(filtered_snp_index_3[i+1])].hm_chrom,y=-np.log10(data3.loc[list(filtered_snp_index_3[i+1])].p_value),color='g')#,label=\"Epigenetic\")\n",
    "    sns.scatterplot(x=data4.loc[list(filtered_snp_index_4[i+1])].hm_chrom,y=-np.log10(data4.loc[list(filtered_snp_index_4[i+1])].p_value),color='y')#,label=\"PhenoAge\")\n",
    "\n",
    "plt.axhline(y = -np.log10(0.05/len(data1)), color = 'r', linestyle = '-',label = \"Significance threshold\")\n",
    "plt.legend()\n",
    "plt.ylabel('-log10 p-value')\n",
    "plt.xlabel('Chromosome ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting metaCCA Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "data1.index = data1.hm_rsid\n",
    "plt.figure(figsize=(15,5))\n",
    "for CHROM in range(23):\n",
    "    sns.scatterplot(x=data1.loc[p_value[CHROM].index].hm_chrom,y=-np.log10(p_value[CHROM]),color='b')#label=\"Chromosome {}\".format(CHROM+1))\n",
    "plt.axhline(y = -np.log10(0.05/len(data1)), color = 'r', linestyle = '-', label = \"Significance threshold\")\n",
    "#plt.legend()\n",
    "plt.ylabel('-log10 p-value')\n",
    "plt.xlabel('Chromosome ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Novel Associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_snps_gwas = []\n",
    "significant_snps_gwas.extend(data_euro_1.hm_rsid.iloc[np.where(data_euro_1.p_value*len(data_euro_1)<0.05)])\n",
    "significant_snps_gwas.extend(data_euro_2.hm_rsid.iloc[np.where(data_euro_2.p_value*len(data_euro_1)<0.05)])\n",
    "significant_snps_gwas.extend(data_euro_3.hm_rsid.iloc[np.where(data_euro_3.p_value*len(data_euro_1)<0.05)])\n",
    "significant_snps_gwas.extend(data_euro_4.hm_rsid.iloc[np.where(data_euro_4.p_value*len(data_euro_1)<0.05)])\n",
    "significant_snps_gwas.extend(data_afri_1.hm_rsid.iloc[np.where(data_afri_1.p_value*len(data_euro_1)<0.05)])\n",
    "significant_snps_gwas.extend(data_afri_2.hm_rsid.iloc[np.where(data_afri_2.p_value*len(data_euro_1)<0.05)])\n",
    "significant_snps_gwas.extend(data_afri_3.hm_rsid.iloc[np.where(data_afri_3.p_value*len(data_euro_1)<0.05)])\n",
    "significant_snps_gwas.extend(data_afri_4.hm_rsid.iloc[np.where(data_afri_4.p_value*len(data_euro_1)<0.05)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_list = list(set(significant_p_value) - set(significant_snps_gwas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Novel associations: ',main_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P-values of novel associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_p_value = []\n",
    "for i in range(23):\n",
    "    for j in range(len(main_list)):\n",
    "        try:sig_p_value.append(p_value[i][main_list[j]]*len(data1))\n",
    "        except:KeyError\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_list + sig_p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_table = pd.DataFrame()\n",
    "final_results_table['rsid']=main_list\n",
    "final_results_table['p_value']=sig_p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
